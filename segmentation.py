from pathlib import Path
from typing import Union, List, Dict, Optional

import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

from mobile_sam import sam_model_registry, SamAutomaticMaskGenerator
from sam2.build_sam import build_sam2_video_predictor


class Segmentation:
    """
    Class for segmenting images using MobileSAM.

    Parameters
    ----------
    checkpoint_path: str
        Path to MobileSAM checkpoint.

    Attributes
    ----------
    mask_generator: SamAutomaticMaskGenerator
        Mask generator.
    img: np.ndarray
        Image to segment.
    masks: List[Dict[str, any]]
        Masks generated by segment_image.
    """
    def __init__(self, checkpoint_path: Union[Path, str]) -> None:
        sam_checkpoint = str(checkpoint_path) + "/mobile_sam.pt"
        model_type = "vit_t"
        sam2_checkpoint = str(checkpoint_path) + "/sam2_hiera_large.pt"
        model_cfg = "sam2_hiera_l.yaml"

        device = "cuda" if torch.cuda.is_available() else "cpu"
        if device == "cuda":
            torch.autocast("cuda", dtype=torch.bfloat16).__enter__()

        # sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
        # sam.to(device=device)
        # sam.eval()

        # self.mask_generator = SamAutomaticMaskGenerator(sam)
        self.predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint, device=device)

    def load_image(self, file: Union[str, Path]) -> np.ndarray:
        """
        Loads image from file.

        Parameters
        ----------
        file: str
            Path to image file.

        Returns
        -------
        np.ndarray
            Image as numpy array.
        """
        self.img = np.array(Image.open(file))
        return self.img

    def plot_image(self, image: Optional[np.ndarray] = None, masks: Union[List[Dict[str, any]], None] = None) -> None:
        """
        Plots original image, masks and image with masks overlayed.

        Parameters
        ----------
        image: np.ndarray
            Original image to plot. If None, uses the image loaded by load_image.
        masks: List[Dict[str, any]]
            Masks to plot. If None, uses the masks generated by segment_image.
        """
        if image is None:
            image = self.img

        plt.figure(figsize=(20,20))
        plt.subplot(1, 3, 1)
        plt.imshow(image)
        plt.axis('off')

        blank_image = 255*np.ones_like(image)

        anns = self._get_anns(masks)

        plt.subplot(1, 3, 2)
        plt.imshow(blank_image)
        plt.imshow(anns)
        plt.axis('off')

        plt.subplot(1, 3, 3)
        plt.imshow(image)
        plt.imshow(anns)
        plt.axis('off')

        plt.show()

    def _get_anns(self, anns: Optional[List[Dict[str, any]]] = None) -> np.ndarray:
        """
        Creates blank image with masks overlayed.

        Parameters
        ----------
        anns: List[Dict[str, any]]
            Masks to overlay. If None, uses the masks generated by segment_image.

        Returns
        -------
        np.ndarray
            Image with masks overlayed.
        """
        if anns is None:
            anns = self.masks
        if len(anns) == 0:
            return
        sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)

        img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))
        img[:,:,3] = 0
        for ann in sorted_anns:
            m = ann['segmentation']
            color_mask = np.concatenate([np.random.random(3), [0.35]])
            img[m] = color_mask

        return img

    def create_segmented_image(self, masks: Optional[List[Dict[str, any]]] = None) -> np.ndarray:
        """
        Creates image with segmentation mask
        
        Parameters
        ----------
        masks: List[Dict[str, any]]
            Masks to overlay. If None, uses the masks generated by segment_image.

        Returns
        -------
        np.ndarray
            Image with masks overlayed.
        """
        masks = masks if masks is not None else self.masks

        sorted_anns = sorted(masks, key=(lambda x: x['area']), reverse=True)
        img = np.zeros((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 1))
        idx = 1
        for ann in sorted_anns:
            m = ann['segmentation']
            img[m] = idx
            idx += 1

        return img

    def segment_image(self, image: Optional[Union[np.ndarray, str]] = None) -> List[Dict[str, any]]:
        """
        Segments image.

        Parameters
        ----------
        image: np.ndarray or str
            Image to segment. If None, uses the image loaded by load_image.

        Returns
        -------
        List[Dict[str, any]]
            List of masks.
        """
        if image is None:
            image = self.img
        if type(image) == str:
            image = self.load_image(image)

        self.masks = self.mask_generator.generate(image)

        return self.masks

    def segment_scene(self, scene_dir: Union[str, Path], sensors: List[str]) -> None:
        """
        Segments all images in the scene.

        Parameters
        ----------
        scene_dir: str or Path
            Path to the scene directory.
        sensors: List[str]
            List of sensors.
        """
        def show_mask(mask, ax, obj_id=None, random_color=False):
            if random_color:
                color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)
            else:
                cmap = plt.get_cmap("tab10")
                cmap_idx = 0 if obj_id is None else obj_id
                color = np.array([*cmap(cmap_idx)[:3], 0.6])
            h, w = mask.shape[-2:]
            mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
            ax.imshow(mask_image)

        scene_dir = Path(scene_dir)
        for sensor in sensors:
            h_p, w_p = (15, 20) if sensor != "ring_front_center" else (20, 15)
            height, width = (1550, 2048) if sensor != "ring_front_center" else (2048, 1550)
            rand_h = np.random.randint(0, height, h_p)
            rand_w = np.random.randint(0, width, w_p)
            points = np.array(list([h, w] for h in rand_h for w in rand_w))
            labels = np.ones(points.shape)
            obj_id = 1
            for point, label in zip(points, labels):
                self.predictor.add_new_points_or_box(
                    inference_state=inference_state,
                    frame_idx = 0,
                    obj_id = obj_id,
                    points = point,
                    label = label,
                )
                obj_id += 1
            video_path = scene_dir / "sensors" / "cameras" / sensor
            frame_names = sorted([f for f in (video_path).iterdir()])
            inference_state = self.predictor.init_state(video_path=str(video_path))
            self.predictor.reset_state(inference_state)
            video_segments = {}
            for out_frame_idx, out_obj_ids, out_mask_logits in self.predictor.propagate_in_video(inference_state):
                video_segments[out_frame_idx] = {
                    out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()
                    for i, out_obj_id in enumerate(out_obj_ids)
                }
            vis_frame_stride = 30
            plt.close("all")
            for out_frame_idx in range(0, len(frame_names), vis_frame_stride):
                plt.figure(figsize=(6, 4))
                plt.title(f"frame {out_frame_idx}")
                plt.imshow(Image.open(video_path / frame_names[out_frame_idx]))
                for out_obj_id, out_mask in video_segments[out_frame_idx].items():
                    show_mask(out_mask, plt.gca(), obj_id=out_obj_id)